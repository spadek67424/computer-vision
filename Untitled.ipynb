{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad64497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/spadek67424/.cache/torch/hub/pytorch_vision_v0.10.0\n",
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /home/spadek67424/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n",
      "22.5%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "64.1%IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (AuxLogits): InceptionAux(\n",
       "    (conv0): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (conv1): BasicConv2d(\n",
       "      (conv): Conv2d(128, 768, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acffa74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "import urllib\n",
    "url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "try: urllib.URLopener().retrieve(url, filename)\n",
    "except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1464c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.1604e-01, -1.7399e-01, -4.4543e-01,  3.3952e-01, -3.3232e-01,\n",
      "        -2.4687e-01,  1.7485e+00, -2.7722e-01, -1.0705e-01, -2.7201e+00,\n",
      "        -6.8264e-01, -4.5814e-01, -4.0169e-01,  7.8553e-02,  2.2644e+00,\n",
      "        -7.1287e-02, -1.1973e+00,  2.3260e-01, -1.0481e-02,  8.9153e-01,\n",
      "         1.3980e+00, -1.5724e+00,  7.9773e-02, -1.0424e+00,  5.3808e-01,\n",
      "        -1.7933e+00, -7.7180e-01, -9.3737e-01, -1.1138e+00, -1.0838e+00,\n",
      "        -4.2681e-03,  3.3813e-01,  1.0190e+00, -6.0967e-01,  1.0344e+00,\n",
      "        -1.2200e+00,  6.2211e-01, -1.1609e+00, -1.6500e-01,  7.0279e-01,\n",
      "         8.6265e-01,  1.1764e+00, -1.3189e-01,  6.2017e-01, -1.3178e-01,\n",
      "        -3.5773e-01, -7.1037e-01,  1.4938e+00, -3.8862e-01, -4.7465e-01,\n",
      "        -8.2960e-01,  6.6274e-01,  5.8458e-01, -1.1612e+00,  9.8651e-01,\n",
      "         1.4156e+00, -2.3546e+00, -7.8426e-01, -2.2310e-01, -3.7628e-01,\n",
      "        -1.7901e-01,  1.1235e+00, -1.4625e+00, -1.0485e+00, -3.4495e-01,\n",
      "        -5.7951e-02,  2.1325e-01,  1.6919e+00,  3.9852e-01, -3.1154e-01,\n",
      "        -1.6090e+00, -5.9252e-01, -1.8796e+00, -1.8635e+00, -7.7956e-01,\n",
      "        -5.2873e-01, -8.3451e-01, -4.5734e-01,  2.5884e-01,  1.6163e+00,\n",
      "        -8.2202e-01,  9.9815e-01,  2.8184e-01,  3.7491e-01,  1.6456e+00,\n",
      "        -3.6196e-01, -6.3535e-01, -5.1766e-01,  1.3306e+00,  1.0800e+00,\n",
      "         1.8858e-01,  1.4120e+00,  3.2559e-01, -1.0983e-01,  1.7303e-01,\n",
      "        -7.7141e-01,  1.0589e+00,  6.1382e-02, -1.8077e+00,  1.3642e+00,\n",
      "         1.1633e+00,  1.5231e+00, -7.1732e-01, -1.5599e-01,  7.1972e-01,\n",
      "        -2.1550e+00, -1.2454e+00,  4.9635e-01,  4.9269e-01,  9.8503e-01,\n",
      "        -4.3753e-01, -9.0211e-01,  1.5125e+00,  2.1687e+00,  6.8782e-01,\n",
      "        -1.9171e+00, -2.0084e+00,  6.1466e-01, -2.1311e+00, -8.9383e-01,\n",
      "        -3.0555e-01, -2.2425e+00, -2.1120e-02, -8.2315e-01, -1.6653e+00,\n",
      "         2.9287e-01, -1.4174e+00,  1.9156e+00,  2.5686e-01,  5.8208e-01,\n",
      "        -2.2613e-02,  7.0669e-02,  6.9531e-01, -1.7216e+00, -2.0211e-01,\n",
      "         7.4151e-01,  9.8415e-01, -5.7274e-01, -1.2164e+00, -1.4442e+00,\n",
      "        -1.0915e+00,  3.9411e-01, -2.0715e+00, -8.2204e-01,  2.0015e+00,\n",
      "        -3.1959e-01,  6.7621e-01, -7.5332e-01,  2.4437e-01,  3.8754e-01,\n",
      "         9.8590e-02,  1.4884e+00,  4.5068e+00,  5.5381e-01,  2.2080e+00,\n",
      "        -2.5899e+00,  7.6851e-01,  4.6458e+00, -1.3291e+00, -6.1942e-01,\n",
      "        -1.9343e-01, -1.7025e+00, -1.3513e+00,  6.6038e-03, -1.7702e-01,\n",
      "        -1.0858e+00, -6.2834e-01, -4.6994e-01, -8.1229e-01,  2.1859e+00,\n",
      "         4.8375e-01, -2.9011e-01, -2.5833e-01,  3.4813e-01,  2.2799e+00,\n",
      "        -1.7574e+00, -7.4095e-01, -6.1765e-01,  5.9486e-01,  6.2689e-01,\n",
      "        -5.5596e-01,  6.6518e-01, -6.1544e-01, -2.3401e-01, -1.2376e+00,\n",
      "         1.4957e+00,  2.7862e+00, -7.8196e-01, -9.3079e-01, -2.5108e+00,\n",
      "        -7.4463e-02, -1.3212e+00,  5.4089e-01, -1.7629e+00, -1.2591e+00,\n",
      "        -1.0839e-03, -1.8255e+00,  6.4702e-01, -2.2141e-01,  1.0351e+00,\n",
      "         1.0771e-01, -2.6570e+00, -1.3100e+00,  5.8879e+00, -1.9984e+00,\n",
      "        -2.2130e+00, -1.5663e+00,  1.2227e+00, -1.6289e+00, -1.7465e+00,\n",
      "        -7.8993e-01, -1.2084e+00, -7.5537e-01,  2.5152e-01,  8.5835e-01,\n",
      "         1.5187e-01,  1.4557e+00, -4.6831e-01,  6.1225e-01, -3.3172e+00,\n",
      "        -9.7985e-01, -1.6874e-01,  5.1209e+00,  3.3830e+00,  5.5592e+00,\n",
      "        -1.3222e+00,  5.9491e-01, -2.5132e+00,  1.2433e+00,  1.2272e+00,\n",
      "         1.8829e+00,  3.3065e+00,  3.2724e+00,  8.6933e-01, -7.3555e-01,\n",
      "         1.1114e+00, -2.3749e-02, -8.8974e-01, -5.7048e-01, -4.0012e-01,\n",
      "         5.5228e-01,  4.2469e-01,  1.1867e+00, -1.1560e+00, -8.0548e-01,\n",
      "         1.5030e-01, -2.8528e-01,  1.8271e+00,  9.0546e+00,  6.3808e+00,\n",
      "         4.8384e+00,  1.2083e+00, -7.2173e-01,  1.1002e-02,  2.5077e-01,\n",
      "         1.2889e+00,  1.5215e+00,  8.8308e+00,  2.1909e+01,  8.2178e+00,\n",
      "         7.4868e+00,  7.9916e+00, -6.3190e-01,  1.4706e-02, -1.2238e-01,\n",
      "         2.6689e-01, -7.6679e-01,  2.0761e+00, -2.7723e-01,  2.8221e+00,\n",
      "         1.2524e+01, -1.3801e+00,  4.5514e-02,  1.1724e+00,  6.2822e-01,\n",
      "        -2.3785e+00, -6.2726e-01,  9.6851e-01, -1.3309e+00,  1.0553e+01,\n",
      "         9.7817e-01, -4.9988e-03, -4.4095e-01,  4.1562e+00, -1.1968e+00,\n",
      "        -7.9154e-01, -1.4966e+00,  1.1295e+00,  2.2966e-01,  5.6101e-01,\n",
      "        -1.1499e+00,  1.9723e-01,  2.9533e-01, -6.1347e-01, -1.3846e+00,\n",
      "        -2.2534e+00,  3.9040e+00, -6.3659e-01, -2.0803e+00, -1.2091e+00,\n",
      "        -7.7959e-01, -1.0213e+00,  1.1655e+00, -4.4070e-01, -1.2710e-01,\n",
      "         1.2373e-01,  7.9697e-01,  6.5468e-01,  4.1709e-01,  2.1031e-01,\n",
      "        -6.4314e-01, -5.7388e-01, -3.1046e-01, -7.1936e-01, -1.2784e-01,\n",
      "         7.9572e-01, -1.1338e+00,  4.9580e-02, -6.5743e-01, -7.3320e-01,\n",
      "         6.3803e-01, -8.2089e-01,  7.9658e-02,  1.0633e+00, -2.1204e+00,\n",
      "        -2.9860e-01,  9.3919e-01,  8.3575e-01,  1.1989e+00, -1.2823e+00,\n",
      "        -5.1108e-01,  1.2019e+00,  2.7106e+00, -1.8145e-01, -6.3555e-01,\n",
      "        -2.1310e+00, -2.1548e+00, -5.5699e-01,  1.9636e+00, -1.1142e+00,\n",
      "         5.6491e-02,  2.6749e-01, -1.1399e+00, -4.2135e-01, -9.3675e-01,\n",
      "         2.6537e-02,  6.5398e-01,  3.3894e-01,  3.2604e-01, -1.0310e+00,\n",
      "        -1.3554e+00, -9.9690e-01, -1.1601e+00, -1.0883e-01, -8.7060e-01,\n",
      "         1.2733e+00,  8.9744e-01, -3.8601e-01,  9.5089e-01,  5.1735e-03,\n",
      "        -2.2428e+00, -8.7424e-02, -1.4805e+00,  1.0083e+00, -1.8252e+00,\n",
      "        -1.9724e+00, -2.5273e+00, -2.0569e+00, -4.8700e-01, -1.8542e+00,\n",
      "        -1.8398e-01, -1.1342e+00, -4.6351e-01, -5.5452e-01, -2.4773e-01,\n",
      "        -1.8084e+00, -1.5886e+00,  6.7549e-01, -6.2218e-01, -2.1112e+00,\n",
      "        -6.2941e-01, -2.1879e+00, -5.3448e-01, -1.5841e+00, -1.5216e+00,\n",
      "         3.9543e-01, -1.3424e+00,  2.9286e-01, -3.2963e-01, -1.1723e+00,\n",
      "        -1.0007e+00, -6.1014e-01,  6.4356e-01,  7.3756e-01, -4.8501e-03,\n",
      "        -7.7816e-01,  1.1655e+00, -4.7730e-02,  6.1573e-01,  1.4098e+00,\n",
      "        -4.6699e-01, -1.2317e+00,  8.3922e-01,  5.2904e-01,  8.0789e-01,\n",
      "         1.8144e-02, -8.5778e-01, -5.2987e-01,  2.7525e-01, -4.4853e-01,\n",
      "        -2.7568e-01, -1.9552e+00, -2.5586e+00, -6.7413e-01, -6.3327e-01,\n",
      "        -1.2719e+00, -1.5059e+00,  7.4037e-01, -9.0226e-01, -2.6457e-01,\n",
      "        -2.6931e-01, -2.3468e+00, -1.2352e+00, -7.5997e-01, -7.0364e-02,\n",
      "         1.5239e+00,  4.1589e-01,  5.2996e-01, -4.7376e-01,  8.4227e-02,\n",
      "        -2.8868e-01, -4.8387e-01, -1.9436e-02,  5.2248e-01, -1.2655e+00,\n",
      "        -9.0488e-02, -3.8191e-01, -1.1631e+00, -6.1152e-01,  1.0271e-01,\n",
      "         9.6481e-01,  1.0026e-01,  1.1405e+00, -7.1613e-01, -1.1434e+00,\n",
      "         1.1737e+00, -5.7789e-01, -4.8000e-01,  1.2413e+00, -5.7671e-01,\n",
      "         1.7568e-01,  6.1165e-01,  2.6342e-01, -6.9321e-01, -1.2982e-01,\n",
      "         2.2105e-01,  1.0727e+00, -5.0531e-01, -4.5360e-01,  4.1508e-01,\n",
      "        -1.9715e-01, -2.0920e+00,  1.4427e+00,  4.4368e-01,  1.3049e-01,\n",
      "        -1.3148e+00, -9.1553e-01, -1.9650e+00,  6.2858e-01,  2.1128e-01,\n",
      "         8.3855e-01,  1.9678e-01, -1.7636e+00,  1.3340e+00, -1.2544e+00,\n",
      "        -1.6041e-01,  3.2628e+00, -7.8003e-01,  1.5053e+00,  3.0658e-01,\n",
      "        -4.2817e-01, -5.3254e-01, -2.4543e+00,  9.3928e-01, -5.5506e-01,\n",
      "        -2.0890e+00, -4.5859e-01, -2.4033e-01,  6.4225e-01,  5.3742e-01,\n",
      "         9.2372e-01,  7.6868e-01, -1.6788e+00, -1.3833e+00,  5.0966e-02,\n",
      "         1.7196e+00, -4.0132e-01, -1.5665e+00,  5.6681e-01, -5.7468e-01,\n",
      "        -1.8226e+00, -1.3225e-01, -1.4697e+00, -5.6605e-01, -5.1919e-01,\n",
      "         6.7625e-01, -5.1156e-02,  1.1206e-01, -1.9543e-01, -6.7478e-01,\n",
      "         5.8835e-01,  9.6195e-01, -6.2183e-02, -6.3609e-01, -2.5155e-01,\n",
      "         4.6680e-01, -1.9454e+00, -6.9231e-01, -2.0050e+00, -2.4228e+00,\n",
      "        -2.5035e-01, -7.1833e-01,  6.1097e-01, -1.2968e+00, -3.7700e-01,\n",
      "        -9.9870e-01, -1.2126e+00, -2.5732e+00, -4.2012e-01, -9.9292e-01,\n",
      "         6.1233e-02,  6.0426e-01,  2.8120e-01, -6.3561e-01, -7.7859e-01,\n",
      "        -1.2007e+00, -1.9777e+00,  3.5903e+00,  7.9274e-01, -4.1952e-01,\n",
      "        -7.3162e-01, -1.2478e-01, -3.0081e-01,  9.1600e-01, -5.9866e-01,\n",
      "        -3.5203e-01,  7.8313e-01, -8.4890e-02, -1.8233e+00,  5.3402e-02,\n",
      "        -4.7840e-02,  8.1896e-01, -5.7844e-01, -2.5566e+00,  2.0036e-01,\n",
      "        -9.2900e-01,  2.6485e-01,  7.6854e-01, -1.7075e-01,  1.8680e-01,\n",
      "        -2.4136e-01, -6.2711e-01,  3.0992e+00,  9.2509e-01,  2.6319e-01,\n",
      "        -6.3962e-01, -9.1861e-02, -4.9263e-01,  9.2663e-01, -1.0156e+00,\n",
      "         3.9622e-01, -5.4037e-01,  8.6528e-01,  1.3999e+00, -4.8779e-01,\n",
      "        -3.7613e-01,  7.2363e-01,  2.9163e-01,  9.6030e-01, -1.5678e+00,\n",
      "         7.0326e-01,  1.3172e+00,  4.0958e-01,  6.7468e-03,  5.3456e-01,\n",
      "        -1.4344e-02, -2.0839e+00,  9.2591e-01, -4.2700e-01, -7.5698e-01,\n",
      "         4.9085e-01, -7.3182e-03,  1.6326e+00, -3.5526e-01,  1.1971e+00,\n",
      "        -1.2092e+00,  1.5821e+00, -2.4613e-01, -2.1343e+00,  5.0758e-03,\n",
      "        -1.1095e+00, -1.6582e+00, -1.6223e+00, -4.7869e-01,  2.2908e+00,\n",
      "        -8.5737e-01,  3.0585e+00,  5.3632e-01,  4.3506e-01,  3.4277e-01,\n",
      "        -5.9847e-01,  5.7730e-01, -2.1758e-01,  8.1374e-01, -7.0020e-01,\n",
      "        -1.3377e+00, -8.5074e-01, -3.9357e-02,  7.0146e-02, -1.1785e+00,\n",
      "        -2.2726e+00,  6.2725e-01,  1.1971e+00,  2.0627e-01,  8.6296e-01,\n",
      "         5.1855e-01,  1.2394e-01, -5.8438e-01,  2.0268e+00,  7.3504e-01,\n",
      "        -8.3864e-01, -9.5981e-01, -8.1225e-01,  9.1120e-01, -2.2161e+00,\n",
      "        -1.1149e+00, -1.3630e-01, -7.5338e-01, -6.4100e-01,  5.8103e-01,\n",
      "        -1.0622e+00, -1.1088e+00, -9.1270e-01, -3.2743e-01, -3.7247e-01,\n",
      "         8.7052e-01,  4.4823e-01, -1.2535e+00, -5.0850e-01,  6.7103e-01,\n",
      "        -6.6728e-01, -1.0867e-01,  1.1048e+00, -1.4100e+00, -4.2946e-01,\n",
      "        -1.8668e+00,  9.0128e-01, -2.1531e+00, -1.0695e-01, -1.1806e+00,\n",
      "        -1.5686e+00,  9.6501e-01, -1.0869e+00, -2.2302e+00, -1.2974e+00,\n",
      "        -2.0043e-02,  5.5573e-01,  3.5860e-01, -1.4710e+00,  8.7155e-01,\n",
      "         1.0913e+00, -1.0565e+00,  1.2026e+00, -1.0985e+00,  8.7604e-02,\n",
      "         6.5227e-01,  1.2411e+00, -4.0510e-01,  3.7078e-01, -1.8976e-01,\n",
      "         2.4862e-01, -2.4494e+00,  2.3854e+00, -5.4299e-01,  4.5976e-01,\n",
      "        -2.4660e-01, -1.3137e+00,  3.6883e-01, -9.2724e-01, -5.5420e-01,\n",
      "         3.7707e-01, -6.8748e-01, -7.4685e-01, -3.0793e+00, -6.2461e-01,\n",
      "         1.4700e+00,  2.4290e-01, -5.3125e-02,  1.6851e+00,  6.2313e-01,\n",
      "        -2.0296e+00, -7.7973e-01, -2.8131e+00,  4.0434e-01, -1.8572e+00,\n",
      "        -2.8609e+00,  4.0262e-01,  3.9045e-01,  1.6472e-01, -1.4091e+00,\n",
      "         1.1000e+00,  1.3843e+00,  6.2464e-01, -3.3464e+00,  6.7279e-01,\n",
      "         6.1678e-01, -1.1386e+00,  4.5497e-01,  8.2900e-01,  1.8869e+00,\n",
      "         5.3922e-01, -1.1362e+00,  2.2380e-01,  7.1514e-01,  2.0580e+00,\n",
      "         6.3202e-01, -2.0979e-01, -3.5545e-01,  4.0649e-02, -2.0819e-01,\n",
      "        -8.6911e-01,  1.8522e+00, -4.6859e-01,  4.1996e-01, -7.2517e-01,\n",
      "        -9.0255e-01, -9.6279e-01, -6.8810e-01,  6.7846e-01, -3.1782e-01,\n",
      "         1.1076e+00,  3.3638e-02, -1.2881e+00, -7.5661e-01, -1.0882e+00,\n",
      "        -2.8309e+00,  4.0302e+00, -6.0802e-01, -9.0895e-01,  9.6512e-01,\n",
      "        -2.4202e+00, -5.9384e-01,  3.8406e-01, -1.4945e+00, -2.5454e+00,\n",
      "        -9.6496e-02, -9.4113e-01,  1.7913e-01,  1.2244e+00, -1.1472e+00,\n",
      "        -2.0044e+00, -1.2433e+00, -4.8711e-01,  1.0500e+00, -6.5467e-01,\n",
      "         2.3737e-02, -2.0755e+00,  1.1335e+00,  1.2145e-01,  1.4053e+00,\n",
      "        -4.8214e-01, -1.1088e+00, -5.0488e-01, -2.4638e-01, -1.0877e+00,\n",
      "         3.6325e-02,  2.9787e-01, -8.6314e-01, -6.9924e-01, -4.0378e-02,\n",
      "         1.7461e+00, -4.1445e-02, -3.3177e-01, -5.8086e-01, -1.0946e+00,\n",
      "        -1.1004e+00, -5.7501e-01,  3.5507e-01,  4.5140e-01, -9.3662e-02,\n",
      "         8.0691e-01,  5.7233e-01,  2.0544e+00, -1.9207e-01, -1.0460e+00,\n",
      "        -1.3876e+00,  1.2445e-01, -2.4344e+00, -6.3937e-01,  1.1022e+00,\n",
      "         1.3689e+00, -3.5786e-01,  1.2464e+00,  5.5830e-01, -1.1205e+00,\n",
      "        -1.1630e-01, -2.6348e+00, -1.6776e+00,  7.2694e-01,  3.1647e-01,\n",
      "         3.8868e-01, -1.4457e+00,  9.9705e-01, -4.4707e-02,  8.5593e-01,\n",
      "         5.5893e-01,  1.6585e+00, -4.9519e-01, -9.9609e-01,  1.3840e-02,\n",
      "         2.6676e-01, -1.9781e+00,  9.0206e-01,  9.6988e-01, -3.0888e-01,\n",
      "        -4.3627e-01,  1.0204e+00, -1.8320e-01,  2.3216e+00, -8.6718e-01,\n",
      "         4.0809e-02, -5.0843e-01,  1.7305e+00,  1.6072e-01, -1.6797e+00,\n",
      "        -1.3219e+00,  1.1360e+00, -3.4297e-01,  1.3682e-01, -5.0029e-01,\n",
      "         9.3771e-01,  3.7981e-01, -1.6714e-02,  7.6419e-01,  9.7827e-01,\n",
      "        -1.8079e-02, -5.9273e-01, -1.8069e+00, -2.0304e-01,  3.3848e-01,\n",
      "         1.3217e+00, -1.3832e+00,  2.4535e+00,  4.4295e-01,  3.4817e-01,\n",
      "         3.7443e-01, -1.6857e+00,  1.1779e+00,  8.1779e-01, -6.6455e-01,\n",
      "         3.2335e-01,  1.3307e+00, -5.1606e-02,  7.3320e-01, -1.7569e+00,\n",
      "        -5.3130e-01, -5.9173e-01,  6.0784e-01, -2.4929e+00, -1.2207e+00,\n",
      "         8.9827e-01, -7.7725e-01,  7.3099e-01, -3.6934e-01, -1.2082e+00,\n",
      "        -1.2717e+00, -3.5672e-01, -3.0571e+00,  1.6654e+00, -1.7886e-01,\n",
      "        -2.1129e+00, -1.0383e+00,  8.8716e-01, -1.2364e+00, -2.0476e-01,\n",
      "        -1.4110e+00,  1.0630e+00,  4.5661e-01, -2.4190e-01,  2.0759e-01,\n",
      "        -9.3062e-02,  6.1883e-02, -1.1802e+00,  1.3077e+00, -1.6737e+00,\n",
      "        -7.1761e-01,  1.5060e+00, -9.6936e-01,  1.2062e+00,  1.2500e+00,\n",
      "        -1.1030e-01, -6.9812e-01,  9.0084e-01, -2.0001e+00, -8.5384e-02,\n",
      "        -2.2775e+00, -1.2352e+00,  1.1041e+00, -4.5762e-01,  1.1285e+00,\n",
      "         7.7771e-01, -3.1763e-01,  4.8635e-01,  1.7117e+00,  7.1722e-02,\n",
      "         1.4500e+00, -8.5019e-01, -1.0304e+00,  7.3550e-01, -5.7559e-01,\n",
      "        -7.5352e-02,  7.1378e-01,  9.8572e-01,  9.3773e-01, -9.3400e-01,\n",
      "         9.5756e-01, -1.4557e+00, -1.4195e+00,  8.6826e-01, -5.7533e-02,\n",
      "         6.4629e-01, -8.3325e-01, -5.6692e-01, -1.6945e+00, -1.2451e+00,\n",
      "        -5.2262e-01, -6.9739e-01,  8.8947e-01, -9.5043e-01,  6.0343e-01,\n",
      "         2.3083e-01,  1.3593e+00,  1.2227e+00,  9.5306e-01,  1.2815e+00,\n",
      "         1.5886e+00,  8.3999e-02, -7.5752e-01,  5.5252e-01,  7.2432e-02,\n",
      "         1.0825e+00,  1.7909e+00,  1.8187e+00,  1.7811e-01,  5.4061e-01,\n",
      "         1.0411e+00,  2.0495e+00,  1.3821e+00,  5.2948e-02, -4.2327e-01,\n",
      "        -7.3830e-01,  1.6992e+00, -1.4187e+00, -9.6208e-01, -4.9600e-01,\n",
      "        -6.7047e-01,  4.8331e-01,  1.2001e+00, -8.0693e-01, -4.0178e-01,\n",
      "        -1.3800e+00,  1.2697e+00,  2.0370e-01, -6.2791e-01, -1.3260e-01,\n",
      "        -2.3075e+00, -1.5830e+00,  2.0838e+00,  6.0523e-01, -1.3137e+00,\n",
      "        -1.5119e+00, -1.1603e+00, -5.4230e-02, -4.7246e-01, -1.0175e+00,\n",
      "        -1.0978e+00,  5.8343e-03, -2.4028e-01,  1.2852e+00,  5.9858e-01,\n",
      "         7.5909e-02, -1.0459e+00, -1.8810e+00, -1.5596e+00, -2.3620e+00,\n",
      "         1.1685e-02, -4.8784e-01, -1.2814e+00, -9.2548e-01,  3.6810e-01])\n",
      "tensor([2.2263e-10, 2.5661e-10, 1.9561e-10, 4.2883e-10, 2.1903e-10, 2.3857e-10,\n",
      "        1.7547e-09, 2.3144e-10, 2.7437e-10, 2.0115e-11, 1.5430e-10, 1.9314e-10,\n",
      "        2.0435e-10, 3.3033e-10, 2.9394e-09, 2.8436e-10, 9.2226e-11, 3.8534e-10,\n",
      "        3.0219e-10, 7.4476e-10, 1.2359e-09, 6.3379e-11, 3.3073e-10, 1.0768e-10,\n",
      "        5.2302e-10, 5.0816e-11, 1.4114e-10, 1.1960e-10, 1.0026e-10, 1.0331e-10,\n",
      "        3.0407e-10, 4.2824e-10, 8.4604e-10, 1.6598e-10, 8.5918e-10, 9.0160e-11,\n",
      "        5.6887e-10, 9.5643e-11, 2.5892e-10, 6.1667e-10, 7.2356e-10, 9.9024e-10,\n",
      "        2.6764e-10, 5.6777e-10, 2.6767e-10, 2.1354e-10, 1.5008e-10, 1.3601e-09,\n",
      "        2.0704e-10, 1.8997e-10, 1.3321e-10, 5.9246e-10, 5.4792e-10, 9.5612e-11,\n",
      "        8.1897e-10, 1.2578e-09, 2.8989e-11, 1.3939e-10, 2.4431e-10, 2.0961e-10,\n",
      "        2.5532e-10, 9.3921e-10, 7.0744e-11, 1.0703e-10, 2.1628e-10, 2.8818e-10,\n",
      "        3.7796e-10, 1.6581e-09, 4.5489e-10, 2.2363e-10, 6.1104e-11, 1.6885e-10,\n",
      "        4.6618e-11, 4.7373e-11, 1.4005e-10, 1.7997e-10, 1.3256e-10, 1.9329e-10,\n",
      "        3.9559e-10, 1.5375e-09, 1.3423e-10, 8.2856e-10, 4.0479e-10, 4.4428e-10,\n",
      "        1.5831e-09, 2.1264e-10, 1.6177e-10, 1.8198e-10, 1.1553e-09, 8.9924e-10,\n",
      "        3.6875e-10, 1.2533e-09, 4.2290e-10, 2.7361e-10, 3.6306e-10, 1.4119e-10,\n",
      "        8.8048e-10, 3.2471e-10, 5.0089e-11, 1.1948e-09, 9.7738e-10, 1.4006e-09,\n",
      "        1.4904e-10, 2.6127e-10, 6.2719e-10, 3.5394e-11, 8.7891e-11, 5.0164e-10,\n",
      "        4.9981e-10, 8.1776e-10, 1.9716e-10, 1.2389e-10, 1.3858e-09, 2.6712e-09,\n",
      "        6.0750e-10, 4.4901e-11, 4.0982e-11, 5.6464e-10, 3.6249e-11, 1.2492e-10,\n",
      "        2.2497e-10, 3.2428e-11, 2.9899e-10, 1.3407e-10, 5.7757e-11, 4.0928e-10,\n",
      "        7.4009e-11, 2.0738e-09, 3.9481e-10, 5.4655e-10, 2.9855e-10, 3.2774e-10,\n",
      "        6.1207e-10, 5.4592e-11, 2.4949e-10, 6.4101e-10, 8.1704e-10, 1.7222e-10,\n",
      "        9.0478e-11, 7.2049e-11, 1.0252e-10, 4.5289e-10, 3.8476e-11, 1.3422e-10,\n",
      "        2.2598e-09, 2.2184e-10, 6.0049e-10, 1.4377e-10, 3.8991e-10, 4.4993e-10,\n",
      "        3.3702e-10, 1.3528e-09, 2.7677e-08, 5.3131e-10, 2.7781e-09, 2.2911e-11,\n",
      "        6.5856e-10, 3.1802e-08, 8.0836e-11, 1.6437e-10, 2.5167e-10, 5.5650e-11,\n",
      "        7.9065e-11, 3.0740e-10, 2.5583e-10, 1.0311e-10, 1.6291e-10, 1.9087e-10,\n",
      "        1.3554e-10, 2.7174e-09, 4.9536e-10, 2.2848e-10, 2.3585e-10, 4.3254e-10,\n",
      "        2.9853e-09, 5.2674e-11, 1.4556e-10, 1.6466e-10, 5.5358e-10, 5.7159e-10,\n",
      "        1.7514e-10, 5.9391e-10, 1.6503e-10, 2.4166e-10, 8.8583e-11, 1.3627e-09,\n",
      "        4.9531e-09, 1.3971e-10, 1.2039e-10, 2.4797e-11, 2.8346e-10, 8.1482e-11,\n",
      "        5.2449e-10, 5.2388e-11, 8.6700e-11, 3.0504e-10, 4.9208e-11, 5.8322e-10,\n",
      "        2.4472e-10, 8.5978e-10, 3.4010e-10, 2.1425e-11, 8.2398e-11, 1.1013e-07,\n",
      "        4.1394e-11, 3.3400e-11, 6.3766e-11, 1.0372e-09, 5.9895e-11, 5.3254e-11,\n",
      "        1.3860e-10, 9.1209e-11, 1.4348e-10, 3.9270e-10, 7.2046e-10, 3.5546e-10,\n",
      "        1.3093e-09, 1.9118e-10, 5.6329e-10, 1.1071e-11, 1.1463e-10, 2.5796e-10,\n",
      "        5.1145e-08, 8.9960e-09, 7.9283e-08, 8.1399e-11, 5.5360e-10, 2.4739e-11,\n",
      "        1.0588e-09, 1.0418e-09, 2.0070e-09, 8.3338e-09, 8.0543e-09, 7.2841e-10,\n",
      "        1.4635e-10, 9.2791e-10, 2.9821e-10, 1.2544e-10, 1.7261e-10, 2.0467e-10,\n",
      "        5.3050e-10, 4.6695e-10, 1.0005e-09, 9.6111e-11, 1.3646e-10, 3.5490e-10,\n",
      "        2.2958e-10, 1.8981e-09, 2.6133e-06, 1.8030e-07, 3.8560e-08, 1.0224e-09,\n",
      "        1.4838e-10, 3.0875e-10, 3.9241e-10, 1.1081e-09, 1.3983e-09, 2.0892e-06,\n",
      "        9.9990e-01, 1.1319e-06, 5.4487e-07, 9.0273e-07, 1.6233e-10, 3.0990e-10,\n",
      "        2.7020e-10, 3.9879e-10, 1.4185e-10, 2.4349e-09, 2.3144e-10, 5.1340e-09,\n",
      "        8.3909e-05, 7.6820e-11, 3.1959e-10, 9.8630e-10, 5.7235e-10, 2.8304e-11,\n",
      "        1.6309e-10, 8.0436e-10, 8.0692e-11, 1.1693e-05, 8.1217e-10, 3.0385e-10,\n",
      "        1.9649e-10, 1.9492e-08, 9.2275e-11, 1.3838e-10, 6.8372e-11, 9.4485e-10,\n",
      "        3.8421e-10, 5.3515e-10, 9.6706e-11, 3.7195e-10, 4.1029e-10, 1.6535e-10,\n",
      "        7.6474e-11, 3.2078e-11, 1.5147e-08, 1.6157e-10, 3.8137e-11, 9.1148e-11,\n",
      "        1.4004e-10, 1.0997e-10, 9.7954e-10, 1.9654e-10, 2.6893e-10, 3.4560e-10,\n",
      "        6.7757e-10, 5.8770e-10, 4.6342e-10, 3.7685e-10, 1.6052e-10, 1.7203e-10,\n",
      "        2.2387e-10, 1.4874e-10, 2.6873e-10, 6.7672e-10, 9.8276e-11, 3.2090e-10,\n",
      "        1.5824e-10, 1.4669e-10, 5.7800e-10, 1.3438e-10, 3.3070e-10, 8.8438e-10,\n",
      "        3.6640e-11, 2.2654e-10, 7.8112e-10, 7.0436e-10, 1.0128e-09, 8.4707e-11,\n",
      "        1.8318e-10, 1.0159e-09, 4.5923e-09, 2.5470e-10, 1.6174e-10, 3.6253e-11,\n",
      "        3.5401e-11, 1.7496e-10, 2.1759e-09, 1.0021e-10, 3.2312e-10, 3.9903e-10,\n",
      "        9.7679e-11, 2.0038e-10, 1.1968e-10, 3.1359e-10, 5.8729e-10, 4.2858e-10,\n",
      "        4.2309e-10, 1.0891e-10, 7.8737e-11, 1.1269e-10, 9.5721e-11, 2.7389e-10,\n",
      "        1.2786e-10, 1.0910e-09, 7.4918e-10, 2.0758e-10, 7.9031e-10, 3.0696e-10,\n",
      "        3.2419e-11, 2.7981e-10, 6.9477e-11, 8.3698e-10, 4.9223e-11, 4.2484e-11,\n",
      "        2.4392e-11, 3.9044e-11, 1.8764e-10, 4.7816e-11, 2.5406e-10, 9.8232e-11,\n",
      "        1.9210e-10, 1.7539e-10, 2.3837e-10, 5.0057e-11, 6.2362e-11, 6.0006e-10,\n",
      "        1.6392e-10, 3.6978e-11, 1.6274e-10, 3.4247e-11, 1.7894e-10, 6.2641e-11,\n",
      "        6.6686e-11, 4.5349e-10, 7.9769e-11, 4.0928e-10, 2.1962e-10, 9.4561e-11,\n",
      "        1.1226e-10, 1.6590e-10, 5.8120e-10, 6.3848e-10, 3.0390e-10, 1.4024e-10,\n",
      "        9.7948e-10, 2.9114e-10, 5.6525e-10, 1.2505e-09, 1.9144e-10, 8.9103e-11,\n",
      "        7.0681e-10, 5.1831e-10, 6.8500e-10, 3.1097e-10, 1.2951e-10, 1.7977e-10,\n",
      "        4.0214e-10, 1.9500e-10, 2.3180e-10, 4.3223e-11, 2.3641e-11, 1.5562e-10,\n",
      "        1.6211e-10, 8.5595e-11, 6.7738e-11, 6.4028e-10, 1.2388e-10, 2.3439e-10,\n",
      "        2.3328e-10, 2.9216e-11, 8.8796e-11, 1.4282e-10, 2.8463e-10, 1.4017e-09,\n",
      "        4.6286e-10, 5.1879e-10, 1.9014e-10, 3.3221e-10, 2.2880e-10, 1.8823e-10,\n",
      "        2.9950e-10, 5.1492e-10, 8.6147e-11, 2.7896e-10, 2.0844e-10, 9.5434e-11,\n",
      "        1.6567e-10, 3.3841e-10, 8.0140e-10, 3.3758e-10, 9.5529e-10, 1.4922e-10,\n",
      "        9.7329e-11, 9.8755e-10, 1.7134e-10, 1.8896e-10, 1.0566e-09, 1.7154e-10,\n",
      "        3.6402e-10, 5.6295e-10, 3.9741e-10, 1.5268e-10, 2.6820e-10, 3.8092e-10,\n",
      "        8.9268e-10, 1.8424e-10, 1.9401e-10, 4.6249e-10, 2.5073e-10, 3.7696e-11,\n",
      "        1.2924e-09, 4.7590e-10, 3.4794e-10, 8.1999e-11, 1.2224e-10, 4.2800e-11,\n",
      "        5.7256e-10, 3.7721e-10, 7.0634e-10, 3.7179e-10, 5.2350e-11, 1.1593e-09,\n",
      "        8.7107e-11, 2.6011e-10, 7.9774e-09, 1.3998e-10, 1.3759e-09, 4.1494e-10,\n",
      "        1.9901e-10, 1.7929e-10, 2.6238e-11, 7.8119e-10, 1.7530e-10, 3.7809e-11,\n",
      "        1.9305e-10, 2.4014e-10, 5.8044e-10, 5.2267e-10, 7.6913e-10, 6.5867e-10,\n",
      "        5.6980e-11, 7.6575e-11, 3.2134e-10, 1.7047e-09, 2.0443e-10, 6.3754e-11,\n",
      "        5.3827e-10, 1.7189e-10, 4.9352e-11, 2.6754e-10, 7.0231e-11, 1.7338e-10,\n",
      "        1.8170e-10, 6.0051e-10, 2.9015e-10, 3.4159e-10, 2.5117e-10, 1.5552e-10,\n",
      "        5.4999e-10, 7.9910e-10, 2.8696e-10, 1.6165e-10, 2.3746e-10, 4.8704e-10,\n",
      "        4.3649e-11, 1.5281e-10, 4.1120e-11, 2.7079e-11, 2.3774e-10, 1.4889e-10,\n",
      "        5.6257e-10, 8.3489e-11, 2.0946e-10, 1.1249e-10, 9.0827e-11, 2.3298e-11,\n",
      "        2.0062e-10, 1.1314e-10, 3.2466e-10, 5.5880e-10, 4.0453e-10, 1.6173e-10,\n",
      "        1.4018e-10, 9.1909e-11, 4.2260e-11, 1.1069e-08, 6.7470e-10, 2.0074e-10,\n",
      "        1.4692e-10, 2.6955e-10, 2.2604e-10, 7.6321e-10, 1.6782e-10, 2.1476e-10,\n",
      "        6.6826e-10, 2.8052e-10, 4.9314e-11, 3.2213e-10, 2.9111e-10, 6.9263e-10,\n",
      "        1.7125e-10, 2.3688e-11, 3.7312e-10, 1.2061e-10, 3.9798e-10, 6.5858e-10,\n",
      "        2.5744e-10, 3.6810e-10, 2.3989e-10, 1.6311e-10, 6.7730e-09, 7.7018e-10,\n",
      "        3.9732e-10, 1.6108e-10, 2.7857e-10, 1.8659e-10, 7.7137e-10, 1.1060e-10,\n",
      "        4.5385e-10, 1.7789e-10, 7.2547e-10, 1.2383e-09, 1.8749e-10, 2.0964e-10,\n",
      "        6.2965e-10, 4.0878e-10, 7.9779e-10, 6.3673e-11, 6.1696e-10, 1.1399e-09,\n",
      "        4.5995e-10, 3.0744e-10, 5.2118e-10, 3.0103e-10, 3.8001e-11, 7.7081e-10,\n",
      "        1.9925e-10, 1.4324e-10, 4.9889e-10, 3.0315e-10, 1.5627e-09, 2.1407e-10,\n",
      "        1.0109e-09, 9.1137e-11, 1.4857e-09, 2.3875e-10, 3.6135e-11, 3.0693e-10,\n",
      "        1.0069e-10, 5.8167e-11, 6.0294e-11, 1.8921e-10, 3.0179e-09, 1.2956e-10,\n",
      "        6.5031e-09, 5.2210e-10, 4.7182e-10, 4.3023e-10, 1.6785e-10, 5.4394e-10,\n",
      "        2.4566e-10, 6.8903e-10, 1.5161e-10, 8.0147e-11, 1.3043e-10, 2.9359e-10,\n",
      "        3.2756e-10, 9.3980e-11, 3.1468e-11, 5.7180e-10, 1.0109e-09, 3.7533e-10,\n",
      "        7.2379e-10, 5.1290e-10, 3.4567e-10, 1.7023e-10, 2.3176e-09, 6.3688e-10,\n",
      "        1.3201e-10, 1.1695e-10, 1.3554e-10, 7.5956e-10, 3.3295e-11, 1.0015e-10,\n",
      "        2.6646e-10, 1.4376e-10, 1.6086e-10, 5.4597e-10, 1.0557e-10, 1.0075e-10,\n",
      "        1.2259e-10, 2.2011e-10, 2.1041e-10, 7.2928e-10, 4.7808e-10, 8.7186e-11,\n",
      "        1.8365e-10, 5.9739e-10, 1.5669e-10, 2.7393e-10, 9.2177e-10, 7.4554e-11,\n",
      "        1.9876e-10, 4.7217e-11, 7.5206e-10, 3.5463e-11, 2.7440e-10, 9.3774e-11,\n",
      "        6.3618e-11, 8.0155e-10, 1.0299e-10, 3.2829e-11, 8.3442e-11, 2.9932e-10,\n",
      "        5.3234e-10, 4.3709e-10, 7.0143e-11, 7.3004e-10, 9.0943e-10, 1.0617e-10,\n",
      "        1.0165e-09, 1.0180e-10, 3.3333e-10, 5.8629e-10, 1.0564e-09, 2.0366e-10,\n",
      "        4.4245e-10, 2.5259e-10, 3.9157e-10, 2.6369e-11, 3.3173e-09, 1.7743e-10,\n",
      "        4.8362e-10, 2.3864e-10, 8.2092e-11, 4.4159e-10, 1.2082e-10, 1.7545e-10,\n",
      "        4.4524e-10, 1.5355e-10, 1.4470e-10, 1.4044e-11, 1.6352e-10, 1.3281e-09,\n",
      "        3.8933e-10, 2.8957e-10, 1.6469e-09, 5.6945e-10, 4.0122e-11, 1.4002e-10,\n",
      "        1.8328e-11, 4.5755e-10, 4.7672e-11, 1.7472e-11, 4.5676e-10, 4.5123e-10,\n",
      "        3.6005e-10, 7.4626e-11, 9.1744e-10, 1.2191e-09, 5.7031e-10, 1.0752e-11,\n",
      "        5.9844e-10, 5.6584e-10, 9.7801e-11, 4.8131e-10, 6.9962e-10, 2.0152e-09,\n",
      "        5.2362e-10, 9.8035e-11, 3.8197e-10, 6.2433e-10, 2.3911e-09, 5.7453e-10,\n",
      "        2.4758e-10, 2.1402e-10, 3.1804e-10, 2.4798e-10, 1.2805e-10, 1.9465e-09,\n",
      "        1.9113e-10, 4.6475e-10, 1.4788e-10, 1.2384e-10, 1.1660e-10, 1.5346e-10,\n",
      "        6.0184e-10, 2.2223e-10, 9.2444e-10, 3.1582e-10, 8.4218e-11, 1.4330e-10,\n",
      "        1.0286e-10, 1.8005e-11, 1.7184e-08, 1.6625e-10, 1.2305e-10, 8.0164e-10,\n",
      "        2.7149e-11, 1.6863e-10, 4.4836e-10, 6.8516e-11, 2.3953e-11, 2.7728e-10,\n",
      "        1.1915e-10, 3.6528e-10, 1.0389e-09, 9.6962e-11, 4.1148e-11, 8.8082e-11,\n",
      "        1.8762e-10, 8.7268e-10, 1.5868e-10, 3.1271e-10, 3.8322e-11, 9.4862e-10,\n",
      "        3.4481e-10, 1.2449e-09, 1.8856e-10, 1.0076e-10, 1.8432e-10, 2.3869e-10,\n",
      "        1.0291e-10, 3.1667e-10, 4.1133e-10, 1.2882e-10, 1.5176e-10, 2.9329e-10,\n",
      "        1.7505e-09, 2.9298e-10, 2.1915e-10, 1.7083e-10, 1.0221e-10, 1.0161e-10,\n",
      "        1.7183e-10, 4.3555e-10, 4.7960e-10, 2.7807e-10, 6.8433e-10, 5.4124e-10,\n",
      "        2.3827e-09, 2.5201e-10, 1.0729e-10, 7.6246e-11, 3.4585e-10, 2.6766e-11,\n",
      "        1.6112e-10, 9.1945e-10, 1.2004e-09, 2.1351e-10, 1.0621e-09, 5.3370e-10,\n",
      "        9.9589e-11, 2.7185e-10, 2.1905e-11, 5.7052e-11, 6.3174e-10, 4.1906e-10,\n",
      "        4.5044e-10, 7.1940e-11, 8.2765e-10, 2.9202e-10, 7.1872e-10, 5.3404e-10,\n",
      "        1.6036e-09, 1.8611e-10, 1.1278e-10, 3.0963e-10, 3.9874e-10, 4.2241e-11,\n",
      "        7.5265e-10, 8.0546e-10, 2.2423e-10, 1.9741e-10, 8.4721e-10, 2.5425e-10,\n",
      "        3.1125e-09, 1.2830e-10, 3.1809e-10, 1.8366e-10, 1.7233e-09, 3.5862e-10,\n",
      "        5.6933e-11, 8.1425e-11, 9.5103e-10, 2.1671e-10, 3.5015e-10, 1.8517e-10,\n",
      "        7.7997e-10, 4.4646e-10, 3.0031e-10, 6.5572e-10, 8.1225e-10, 2.9990e-10,\n",
      "        1.6882e-10, 5.0129e-11, 2.4926e-10, 4.2838e-10, 1.1451e-09, 7.6582e-11,\n",
      "        3.5514e-09, 4.7556e-10, 4.3255e-10, 4.4407e-10, 5.6590e-11, 9.9175e-10,\n",
      "        6.9182e-10, 1.5712e-10, 4.2195e-10, 1.1554e-09, 2.9002e-10, 6.3571e-10,\n",
      "        5.2700e-11, 1.7951e-10, 1.6898e-10, 5.6081e-10, 2.5244e-11, 9.0096e-11,\n",
      "        7.4980e-10, 1.4037e-10, 6.3431e-10, 2.1107e-10, 9.1223e-11, 8.5614e-11,\n",
      "        2.1375e-10, 1.4360e-11, 1.6148e-09, 2.5536e-10, 3.6914e-11, 1.0812e-10,\n",
      "        7.4152e-10, 8.8689e-11, 2.4883e-10, 7.4480e-11, 8.8410e-10, 4.8210e-10,\n",
      "        2.3976e-10, 3.7583e-10, 2.7824e-10, 3.2487e-10, 9.3817e-11, 1.1292e-09,\n",
      "        5.7272e-11, 1.4900e-10, 1.3768e-09, 1.1584e-10, 1.0202e-09, 1.0658e-09,\n",
      "        2.7348e-10, 1.5193e-10, 7.5173e-10, 4.1323e-11, 2.8038e-10, 3.1315e-11,\n",
      "        8.8793e-11, 9.2117e-10, 1.9324e-10, 9.4391e-10, 6.6464e-10, 2.2227e-10,\n",
      "        4.9665e-10, 1.6913e-09, 3.2808e-10, 1.3019e-09, 1.3050e-10, 1.0898e-10,\n",
      "        6.3717e-10, 1.7173e-10, 2.8321e-10, 6.2348e-10, 8.1832e-10, 7.7998e-10,\n",
      "        1.2001e-10, 7.9560e-10, 7.1223e-11, 7.3854e-11, 7.2763e-10, 2.8830e-10,\n",
      "        5.8279e-10, 1.3273e-10, 1.7323e-10, 5.6093e-11, 8.7919e-11, 1.8108e-10,\n",
      "        1.5204e-10, 7.4324e-10, 1.1805e-10, 5.5834e-10, 3.8467e-10, 1.1889e-09,\n",
      "        1.0372e-09, 7.9203e-10, 1.0999e-09, 1.4954e-09, 3.3213e-10, 1.4317e-10,\n",
      "        5.3063e-10, 3.2831e-10, 9.0144e-10, 1.8307e-09, 1.8822e-09, 3.6491e-10,\n",
      "        5.2434e-10, 8.6491e-10, 2.3710e-09, 1.2164e-09, 3.2198e-10, 1.9999e-10,\n",
      "        1.4595e-10, 1.6702e-09, 7.3906e-11, 1.1668e-10, 1.8596e-10, 1.5619e-10,\n",
      "        4.9514e-10, 1.0140e-09, 1.3627e-10, 2.0433e-10, 7.6828e-11, 1.0871e-09,\n",
      "        3.7437e-10, 1.6298e-10, 2.6745e-10, 3.0387e-11, 6.2714e-11, 2.4536e-09,\n",
      "        5.5934e-10, 8.2092e-11, 6.7332e-11, 9.5706e-11, 2.8926e-10, 1.9039e-10,\n",
      "        1.1039e-10, 1.0188e-10, 3.0716e-10, 2.4015e-10, 1.1041e-09, 5.5564e-10,\n",
      "        3.2946e-10, 1.0730e-10, 4.6548e-11, 6.4198e-11, 2.8775e-11, 3.0896e-10,\n",
      "        1.8749e-10, 8.4790e-11, 1.2103e-10, 4.4126e-10])\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0])\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783250cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-01-26 23:42:45--  https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 10472 (10K) [text/plain]\n",
      "Saving to: imagenet_classes.txt.1\n",
      "\n",
      "imagenet_classes.tx 100%[===================>]  10.23K  --.-KB/s    in 0.007s  \n",
      "\n",
      "2024-01-26 23:42:45 (1.38 MB/s) - imagenet_classes.txt.1 saved [10472/10472]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download ImageNet labels\n",
    "!wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "564bd347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.9998961687088013\n",
      "white wolf 8.390878065256402e-05\n",
      "Arctic fox 1.1692828593368176e-05\n",
      "Eskimo dog 2.61332820628013e-06\n",
      "Great Pyrenees 2.089197550958488e-06\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
